{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from koe.model_utils import get_or_error\n",
    "from koe.models import Database\n",
    "from koe.sequence_utils import get_sequences\n",
    "from koe.storage_utils import get_sids_tids\n",
    "from root.models import User\n",
    "from koe.cluster_analysis_utils import SimpleNameMerger, NameMerger, get_syllable_labels\n",
    "from koe.sequence_utils import songs_to_syl_seqs\n",
    "from koe.sequence_utils import calc_class_ajacency, calc_class_dist_by_adjacency\n",
    "\n",
    "from nltk import ngrams\n",
    "\n",
    "from koe.models import Segment, AudioFile\n",
    "from root.models import ExtraAttr, ExtraAttrValue\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "from django.conf import settings\n",
    "from koe.ts_utils import extract_tensor_metadata, write_metadata, bytes_to_ndarray, get_rawdata_from_binary\n",
    "from koe.model_utils import natural_order\n",
    "from scipy.cluster.hierarchy import cut_tree\n",
    "\n",
    "import colorlover as cl\n",
    "nCategoricalColours = 11\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = get_or_error(Database, dict(name='Bellbird_TMI'))\n",
    "annotator_name = 'wesley'\n",
    "label_level = 'label'\n",
    "\n",
    "sids, tids = get_sids_tids(database)\n",
    "annotator = get_or_error(User, dict(username__iexact=annotator_name))\n",
    "\n",
    "label_arr, syl_label_enum_arr = get_syllable_labels(annotator, label_level, sids)\n",
    "\n",
    "enum2label = {enum: label for enum, label in enumerate(label_arr)}\n",
    "sid2enumlabel = {sid: enum_label for sid, enum_label in zip(sids, syl_label_enum_arr)}\n",
    "\n",
    "adjacency_mat_sym, _ = calc_class_ajacency(database, syl_label_enum_arr, enum2label, sid2enumlabel,\n",
    "                                           count_style='symmetric', count_circular=False)\n",
    "\n",
    "adjacency_mat_asym, _ = calc_class_ajacency(database, syl_label_enum_arr, enum2label, sid2enumlabel,\n",
    "                                            count_style='asymmetric', count_circular=False)\n",
    "\n",
    "adjacency_mat_sep, _ = calc_class_ajacency(database, syl_label_enum_arr, enum2label, sid2enumlabel,\n",
    "                                           count_style='separate', count_circular=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(syl_label_enum_arr)\n",
    "nlabels = len(counter)\n",
    "frequencies = np.array([counter[i] for i in range(nlabels)])\n",
    "\n",
    "adjacency_mat_sym_norm = adjacency_mat_sym / frequencies[:, None]\n",
    "adjacency_mat_asym_norm = adjacency_mat_asym / frequencies[:, None]\n",
    "adjacency_mat_sep_norm = adjacency_mat_sep / frequencies[:, None]\n",
    "\n",
    "# adjacency_mat_bw_norm = adjacency_mat / frequencies\n",
    "# df_norm = pd.DataFrame(distmat, columns=label_arr, index=label_arr)\n",
    "# df_norm.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_spectrogram(Z, name, color_threshold=None, pdf=None):\n",
    "    fig = plt.figure(figsize=(18,18))\n",
    "    ax = fig.gca()\n",
    "    ax.set_title(name)\n",
    "    hierarchy.dendrogram(\n",
    "        Z,\n",
    "        labels=label_arr,\n",
    "        leaf_font_size=9.,\n",
    "        orientation='right',\n",
    "        color_threshold=color_threshold,\n",
    "    )\n",
    "    if pdf:\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "pdf = PdfPages('dendrogram-new.pdf')\n",
    "mats = {\n",
    "    'Symmetric': adjacency_mat_sym_norm,\n",
    "    'Asymmetric': adjacency_mat_asym_norm,\n",
    "    'Separate': adjacency_mat_sep_norm,\n",
    "}\n",
    "for name, mat in mats.items():\n",
    "    Z = hierarchy.linkage(mat, 'average')\n",
    "    plot_spectrogram(Z, name, pdf=pdf)\n",
    "\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise_syntactical_similar_syllables(merged_classes_names, pdf=None):\n",
    "    nClasses = len(merged_classes_names) + 1\n",
    "    if nClasses <= nCategoricalColours:\n",
    "        #     colours = cl.to_numeric(cl.scales[str(nClasses)]['div']['Spectral'])\n",
    "        colours = cl.to_numeric(cl.scales[str(nClasses)]['div']['Spectral'])\n",
    "    else:\n",
    "        colours = cl.to_numeric(cl.interp(cl.scales[str(nCategoricalColours)]['div']['Spectral'], nClasses))\n",
    "    colours = (np.array(colours) / 255.).tolist()\n",
    "    \n",
    "    \n",
    "    # Display clustering:\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.gca()\n",
    "\n",
    "    syl_inds_unused = np.ones((len(sids),))\n",
    "    for cls, colour in zip(merged_classes_names, colours[1:]):\n",
    "        syl_inds = np.where(label_col==cls)\n",
    "        syl_inds_unused[syl_inds] = 0\n",
    "        x=ordination_data[syl_inds, 0]\n",
    "        y=ordination_data[syl_inds, 1]\n",
    "        c = colour\n",
    "\n",
    "        ax.scatter(x=x, y=y, s=100, c=[c], edgecolors=(0,0,0), linewidths=1, label=cls, alpha=0.5)\n",
    "\n",
    "    syl_inds_unused = np.where(syl_inds_unused==1)\n",
    "    x=ordination_data[syl_inds_unused, 0]\n",
    "    y=ordination_data[syl_inds_unused, 1]\n",
    "    c = colours[0]\n",
    "\n",
    "    ax.scatter(x=x, y=y, s=10, c=[c], linewidths=0, label='other', alpha=0.2)\n",
    "    plt.legend(loc=2)\n",
    "    \n",
    "    if pdf:\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def visualise_syllables(merged_classes_names, label_col, tid_col, pdf=None):\n",
    "    fig_w_in = 18\n",
    "    dpi = 72\n",
    "    fig_w_px = int(fig_w_in * dpi)\n",
    "\n",
    "    final_imgs_combs = []\n",
    "    subplot_cols = []\n",
    "    current_subplot_col = 0\n",
    "    for cls in merged_classes_names:\n",
    "        subplot_cols.append([current_subplot_col])\n",
    "\n",
    "        syl_inds = np.where(label_col==cls)\n",
    "        selected_tids = tid_col[syl_inds]\n",
    "        img_dir = 'user_data/spect/fft/syllable'\n",
    "        selected_syl_imgpth = [img_dir + '/' + tid + '.png' for tid in selected_tids]\n",
    "\n",
    "        images = [Image.open(i) for i in selected_syl_imgpth]\n",
    "        widths, heights = zip(*(i.size for i in images))\n",
    "        max_height = max(heights)\n",
    "        total_height = max_height\n",
    "        offset = 20\n",
    "        imgs_combs = []\n",
    "        imgs_comb = np.full((max_height, fig_w_px, 3), 255, dtype=np.uint8)\n",
    "        current_col = 0\n",
    "        col_count = 1\n",
    "        for img in images:\n",
    "            img_arr = np.asarray(img)\n",
    "            width, height = img.size\n",
    "            if current_col + width > fig_w_px:\n",
    "                imgs_combs.append(imgs_comb)\n",
    "                col_count += 1\n",
    "                if col_count <= 2:\n",
    "                    imgs_comb = np.full((max_height, fig_w_px, 3), 255, dtype=np.uint8)\n",
    "                    total_height += (max_height + offset)\n",
    "                    current_subplot_col += 1\n",
    "                    current_col = 0\n",
    "                else:\n",
    "                    imgs_comb = None\n",
    "            \n",
    "            if col_count > 2:\n",
    "                break\n",
    "            imgs_comb[:, current_col:current_col + width] = img_arr\n",
    "            current_col = current_col + width + offset\n",
    "\n",
    "        if imgs_comb is not None:\n",
    "            imgs_combs.append(imgs_comb)\n",
    "        final_imgs_comb = np.full((total_height, fig_w_px, 3), 255, dtype=np.uint8)\n",
    "\n",
    "        current_subplot_col += 1\n",
    "        subplot_cols[-1].append(current_subplot_col)\n",
    "\n",
    "        current_row = 0\n",
    "        for imgs_comb in imgs_combs:\n",
    "            final_imgs_comb[current_row:current_row + max_height, :] = imgs_comb\n",
    "            current_row = current_row + max_height + offset\n",
    "\n",
    "        final_imgs_comb = Image.fromarray(final_imgs_comb)\n",
    "        final_imgs_combs.append(final_imgs_comb)\n",
    "\n",
    "    max_height = max([x.size[1] for x in final_imgs_combs])\n",
    "    total_height_px = max_height * len(merged_classes_names)\n",
    "\n",
    "    total_height_in = total_height_px / dpi\n",
    "\n",
    "    fig = plt.figure(figsize=(fig_w_in, total_height_in))\n",
    "    for i, cls in enumerate(merged_classes_names):\n",
    "        subplot_col = subplot_cols[i]\n",
    "        start_col = subplot_col[0]\n",
    "        span = subplot_col[1] - start_col\n",
    "        ax = plt.subplot2grid((current_subplot_col, 1), (start_col, 0), rowspan=span)\n",
    "#         print('plt.subplot2grid(({}, 1), ({}, 0), rowspan={})'.format(current_subplot_col, start_col, span))\n",
    "        final_imgs_comb = final_imgs_combs[i]\n",
    "        ax.imshow(np.asarray(final_imgs_comb))\n",
    "        ax.axis('off')\n",
    "        ax.set_title(cls)\n",
    "\n",
    "    if pdf:\n",
    "        pdf.savefig(fig)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_percentile(pct, base_pdf_name, tree, label_col, tid_col):\n",
    "    heights = tree[:, 2]\n",
    "    cut_off = np.percentile(heights, pct)\n",
    "    clusters = cut_tree(tree, height=cut_off)\n",
    "\n",
    "    pdf = PdfPages('{}_at_{}pct.pdf'.format(base_pdf_name, pct))\n",
    "\n",
    "    plot_spectrogram(tree, name, color_threshold=cut_off, pdf=pdf)\n",
    "    clustering = clusters[:, 0]\n",
    "\n",
    "    merged_classes_info = {}\n",
    "\n",
    "    for cls_ind, clst_ind in enumerate(clustering):\n",
    "        if clst_ind in merged_classes_info:\n",
    "            merged_classes_info[clst_ind].append(cls_ind)\n",
    "        else:\n",
    "            merged_classes_info[clst_ind] = [cls_ind]\n",
    "\n",
    "    merged_classes_info = {x: y for x, y in merged_classes_info.items() if len(y) > 1}\n",
    "    merged_classes_names_list = [\n",
    "        [label_arr[yi] for yi in y] for y in merged_classes_info.values()\n",
    "    ]\n",
    "\n",
    "    for merged_classes_names in merged_classes_names_list:\n",
    "        visualise_syntactical_similar_syllables(merged_classes_names, pdf)\n",
    "        visualise_syllables(merged_classes_names, label_col, tid_col, pdf)\n",
    "    pdf.close()\n",
    "\n",
    "def analyse_adjacency_matrix(mat, base_pdf_name, label_col, tid_col):\n",
    "    tree = hierarchy.linkage(mat, 'average')\n",
    "    for pct in [5, 10]:\n",
    "        analyse_percentile(pct, base_pdf_name, tree, label_col, tid_col)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ord_id in [24, 127]:\n",
    "    ordination = Ordination.objects.get(id=ord_id)\n",
    "    bytes_path = ordination.get_bytes_path()\n",
    "    bytes_path = os.path.join(settings.BASE_DIR, bytes_path)\n",
    "\n",
    "    sids_path = ordination.get_sids_path()\n",
    "    sids_path = os.path.join(settings.BASE_DIR, sids_path)\n",
    "    sids = bytes_to_ndarray(sids_path, np.int32)\n",
    "    metadata, headers = extract_tensor_metadata(sids, annotator)\n",
    "\n",
    "    ordination_data = get_rawdata_from_binary(bytes_path, len(sids))\n",
    "\n",
    "    label_colid = np.where(np.array(headers)==label_level)[0][0]\n",
    "    tid_colid = np.where(np.array(headers)=='tid')[0][0]\n",
    "    label_col = np.array([metadata[sid][label_colid] for sid in sids])\n",
    "    tid_col = np.array([metadata[sid][tid_colid] for sid in sids])\n",
    "    \n",
    "    for name, mat in mats.items():\n",
    "        base_pdf_name = ordination.dm.database.name + ':' + ordination.get_name() + ':' + name\n",
    "        print('===={}===='.format(base_pdf_name))\n",
    "        analyse_adjacency_matrix(mat, base_pdf_name, label_col, tid_col)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
